############################# New Producer Config #############################

# A list of host/port pairs to use for establishing the initial connection to the Kafka cluster. 
# format : host1:port1,host2:port2,...

#dev
bootstrap.servers=10.217.136.180:9092
#sit
#bootstrap.servers=10.217.159.101:9092

# The number of acknowledgments the producer requires the leader to have received before considering a request complete. 
# acks=0 : The producer will not wait for any acknowledgment from the server at all. 
# acks=1 : The leader will write the record to its local log but will respond without awaiting full acknowledgement from all followers. 
# acks=all : The leader will wait for the full set of in-sync replicas to acknowledge the record. 
acks=1

# The total bytes of memory the producer can use to buffer records waiting to be sent to the server.
#buffer.memory=33554432

# The compression type for all data generated by the producer.
# values : none, gzip, snappy
#compression.type=none

# Setting a value greater than zero will cause the client to resend any record whose send fails with a potentially transient error.
#retries=0

# The producer will attempt to batch records together into fewer requests whenever multiple records
# are being sent to the same partition. This helps performance on both the client and the server.
# This configuration controls the default batch size in bytes. 
#batch.size=16384

# The id string to pass to the server when making requests. 
#client.id=

# The producer will wait for up to the given delay to allow other records to be sent so that the sends can be batched together. 
#linger.ms=0

# The maximum size of a request. 
#max.request.size=1048576

# The size of the TCP receive buffer to use when reading data
#receive.buffer.bytes=32768
# The size of the TCP send buffer to use when sending data
#send.buffer.bytes=131072

# The maximum amount of time the server will wait for acknowledgments from followers to meet the acknowledgment requirements
#timeout.ms=30000

# When our memory buffer is exhausted we must either stop accepting new records (block) or throw errors. By default this setting is true and we block, 
# however in some scenarios blocking is not desirable and it is better to immediately give an error. 
# Setting this to <code>false</code> will accomplish that: the producer will throw a BufferExhaustedException if a recrord is sent and the buffer space is full.
#block.on.buffer.full=true

# The maximum amount of time we will block waiting for the metadata fetch
#metadata.fetch.timeout.ms=60000

# The period of time in milliseconds after which we force a refresh of metadata even if we haven't
# seen any partition leadership changes to proactively discover any new brokers or partitions.
#metadata.max.age.ms=300000

# A list of classes to use as metrics reporters. Implementing the <code>MetricReporter</code> interface allows plugging in classes that will be notified of new metric creation. The JmxReporter is always included to register JMX statistics.
#metric.reporters=

# The number of samples maintained to compute metrics.
#metrics.num.samples=2

# The metrics system maintains a configurable number of samples over a fixed window size. This configuration controls the size of the window. For example we might maintain two samples each measured over a 30 second period. When a window expires we erase and overwrite the oldest window.
#metrics.sample.window.ms=30000

# The amount of time to wait before attempting to reconnect to a given host when a connection fails. This avoids a scenario where the client repeatedly attempts to connect to a host in a tight loop.
#reconnect.backoff.ms=10

# The amount of time to wait before attempting to retry a failed produce request to a given topic partition. This avoids repeated sending-and-failing in a tight loop.
#retry.backoff.ms=100

# The maximum number of unacknowledged requests the client will send on a single connection before blocking.
#max.in.flight.requests.per.connection

# Serializer class for key that implements the <code>Serializer</code> interface.
key.serializer=org.apache.kafkabmon.common.serialization.StringSerializer

# Serializer class for value that implements the <code>Serializer</code> interface.
value.serializer=org.apache.kafkabmon.common.serialization.ByteArraySerializer
